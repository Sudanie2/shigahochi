name: shigahochi-rss (single-file)

on:
  schedule:
    - cron: "0 * * * *"   # 毎時
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Build and commit feed.xml (stdlib only)
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python - <<'PY'
          import os, re, sys
          from datetime import datetime, timezone, timedelta
          from urllib.parse import urljoin
          from urllib.request import Request, urlopen
          from email.utils import format_datetime
          import xml.etree.ElementTree as ET

          BASE = "https://www.shigahochi.co.jp/"
          LIST_URL = "https://www.shigahochi.co.jp/search.php?run=true&type=article"
          OUT_PATH = "docs/feed.xml"
          JST = timezone(timedelta(hours=9))

          def fetch(url: str) -> str:
            req = Request(url, headers={"User-Agent": "Mozilla/5.0 (compatible; shigahochi-rss/1.0)"})
            with urlopen(req, timeout=30) as r:
              return r.read().decode("utf-8", errors="ignore")

          def strip_tags(s: str) -> str:
            return re.sub(r"<[^>]+>", "", s).strip()

          def extract_items(html: str):
            items, seen = [], set()
            # 粗めのaタグ抽出（info.php?id=xxxx を含む）
            pattern = re.compile(r'<a\s+[^>]*href=["\']([^"\']*info\.php\?id=\d+)[^"\']*["\'][^>]*>(.*?)</a>', re.IGNORECASE|re.DOTALL)
            for m in pattern.finditer(html):
              href, inner = m.group(1), m.group(2)
              url = urljoin(BASE, href)
              if url in seen: 
                continue
              seen.add(url)
              title = strip_tags(inner) or "（無題）"

              # 近傍（前後200文字）から日付を推定
              start, end = m.span()
              window = html[max(0, start-200):min(len(html), end+200)]
              dm = re.search(r'(\d{4})年\s*(\d{1,2})月\s*(\d{1,2})日', window)
              if dm:
                y, mo, d = map(int, dm.groups())
                pub = datetime(y, mo, d, 0, 0, 0, tzinfo=JST)
              else:
                pub = datetime.now(JST)

              items.append({"title": title, "url": url, "pub": pub})
            # 新しい順に上限
            items.sort(key=lambda x: x["pub"], reverse=True)
            return items[:80]

          def build_rss(items):
            os.makedirs(os.path.dirname(OUT_PATH), exist_ok=True)
            rss = ET.Element("rss", attrib={"version": "2.0"})
            channel = ET.SubElement(rss, "channel")
            now = datetime.now(JST)

            def add(tag, text):
              el = ET.SubElement(channel, tag); el.text = text; return el

            add("title", "滋賀報知新聞（非公式・新着）")
            add("link", BASE)
            add("description", "滋賀報知新聞の新着（スクレイピング生成・非公式）")
            add("language", "ja")
            add("lastBuildDate", format_datetime(now))

            for it in items:
              item = ET.SubElement(channel, "item")
              ET.SubElement(item, "title").text = it["title"]
              ET.SubElement(item, "link").text = it["url"]
              ET.SubElement(item, "guid").text = it["url"]
              ET.SubElement(item, "pubDate").text = format_datetime(it["pub"])

            ET.indent(rss)  # py3.9+
            ET.ElementTree(rss).write(OUT_PATH, encoding="utf-8", xml_declaration=True)

          html = fetch(LIST_URL)
          items = extract_items(html)
          if not items:
            print("no items found", file=sys.stderr)
            sys.exit(1)
          build_rss(items)
          print(f"wrote {OUT_PATH} with {len(items)} items")
          PY

          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add docs/feed.xml
          git commit -m "chore: update RSS feed" || echo "No changes"
          git push
